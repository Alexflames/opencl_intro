\documentclass[bachelor, och, times]{SCWorks}
% параметр - тип обучения - одно из значений:
%    spec     - специальность
%    bachelor - бакалавриат (по умолчанию)
%    master   - магистратура
% параметр - форма обучения - одно из значений:
%    och   - очное (по умолчанию)
%    zaoch - заочное
% параметр - тип работы - одно из значений:
%    referat    - реферат
%    coursework - курсовая работа (по умолчанию)
%    diploma    - дипломная работа
%    pract      - отчет по практике
%    pract      - отчет о научно-исследовательской работе
%    autoref    - автореферат выпускной работы
%    assignment - задание на выпускную квалификационную работу
%    review     - отзыв руководителя
%    critique   - рецензия на выпускную работу
% параметр - включение шрифта
%    times    - включение шрифта Times New Roman (если установлен)
%               по умолчанию выключен
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage{graphicx}

\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage{xcolor}
\usepackage[english,russian]{babel}

\usepackage[colorlinks=true]{hyperref}


\newcommand{\eqdef}{\stackrel {\rm def}{=}}

\newtheorem{lem}{Лемма}

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Вычисления на видеокартах}

% Курс
\course{3}

% Группа
\group{351}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
%\department{факультета КНиИТ}

% Специальность/направление код - наименование
%\napravlenie{02.03.02 "--- Фундаментальная информатика и информационные технологии}
%\napravlenie{02.03.01 "--- Математическое обеспечение и администрирование информационных систем}
%\napravlenie{09.03.01 "--- Информатика и вычислительная техника}
\napravlenie{09.03.04 "--- Программная инженерия}
%\napravlenie{10.05.01 "--- Компьютерная безопасность}

% Для студентки. Для работы студента следующая команда не нужна.
%\studenttitle{Студентки}

% Фамилия, имя, отчество в родительном падеже
\author{Григорьева Алексея Александровича}

% Заведующий кафедрой
\chtitle{к.\,ф.-м.\,н.} % степень, звание
\chname{С.\,В.\,Миронов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{доцент} %должность, степень, звание
\saname{М.\,С.\,Семенов}

% Руководитель практики от организации (только для практики,
% для остальных типов работ не используется)
\patitle{к.\,ф.-м.\,н., доцент}
\paname{Д.\,Ю.\,Петров}

% Семестр (только для практики, для остальных
% типов работ не используется)
\term{2}

% Наименование практики (только для практики, для остальных
% типов работ не используется)
\practtype{учебная}

% Продолжительность практики (количество недель) (только для практики,
% для остальных типов работ не используется)
\duration{2}

% Даты начала и окончания практики (только для практики, для остальных
% типов работ не используется)
\practStart{01.07.2016}
\practFinish{14.07.2016}

% Год выполнения отчета
\date{2019}

\maketitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering


\tableofcontents

% Раздел "Обозначения и сокращения". Может отсутствовать в работе
%\abbreviations
%\begin{description}
    %\item \foreignlanguage{english}{EVM} "--- %\foreignlanguage{english}{Ethereum Virtual Machine};
%\end{description}

% Раздел "Определения". Может отсутствовать в работе
%\definitions

% Раздел "Определения, обозначения и сокращения". Может отсутствовать в работе.
% Если присутствует, то заменяет собой разделы "Обозначения и сокращения" и "Определения"
%\defabbr


% Раздел "Введение"
\intro
Ранние видеокарты использовались для решения узкоспециализированных задач по эффективному отображению
графических элементов на экране. До определенного момента их развитие происходило параллельно с процессорами, 
и функционал определялся стремительно развивавшейся игровой индустрией. С появлением у разработчиков
компьютерных игр желания самостоятельно программировать шейдеры, были разработаны программные
средства, способные решать широкий спектр задач. 

Одновременно с этим рост производительности процессоров сильно замедлился, и достигался либо за счет
увеличения количество ядер, либо за счет некоторых оптимизаций в них. Однако, для задач с крупными вычислениями
этого было недостаточно, и сравнения производительности видеокарт и процессоров показали большую разницу в показателях~\ref{flops}.

Причиной этого является различие в количестве ядер как следствие слабой масштабируемости процессоров. 
%https://www.karlrupp.net/2016/08/flops-per-cycle-for-cpus-gpus-and-xeon-phis/

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.35]{screenshots/flops}
	\caption{Теоретический максимум количества операций с плавающей запятой в такт для GPU и CPU на 2016 год. 
	График наилучшего по производительности процессора изображен снизу.}\label{flops}
\end{figure}  

В связи с тем что видеокарты созданы под решение определенного класса задач, алгоритмы должны обладать
определенными свойствами чтобы решение с использованием GPU было эффективней чем на процессоре. В данной работе
рассматривается архитектура вычислительных устройств видеокарты и связанных с ними особенностями, которые
влияют на проектирование алгоритмов.

В практической части рассматриваются не только реализация алгоритмов на видеокарте, но и возможные 
оптимизации по количеству вычислений и обращений к памяти.

При выполнении курсовой работы были поставлены следующие цели:
\begin{itemize}
	\item ознакомиться с теорией, необходимой для написания эффективных алгоритмов для видеокарты 
	с использованием OpenCL;
	\item понять свойства архитектуры видеокарты и тем самым научиться оптимизировать алгоритмы;
	\item получить практический опыт разработки программ на видеокартах с помощью OpenCL.
\end{itemize}

\section{Краткая теория}
Составление эффективных алгоритмов вычисления на видеокарте в значительной степени отличается 
от привычных алгоритмов, исполняющихся на процессоре. При составлении программного кода необходимо 
учитывать как и общие особенности видеокарт, так и, возможно, характеристики конкретного устройства, 
для которого программируется алгоритм.

В данном разделе будет рассмотрена типовая модель видеокарты и основные понятия \foreignlanguage{english}{OpenCL},
с которыми будем оперировать в данной работе.

\subsection{Типовая модель видеокарты}
Рассмотрим следующую архитектуру вычислительного устройства, используемого в видеокартах
\foreignlanguage{english}{Nvidia} \ref{SM}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{screenshots/videocard-base}
	\caption{Архитектура потокого мультипроцессора Fermi.}\label{SM}
\end{figure}

Вычислительное устройство в архитектуре Nvidia имеет 32 \textbf{ядра} (CUDA cores), 
каждое из которых в состоянии работы является \textbf{потоком}. 
В отличии от процессора, ядра выполняют более узкий набор задач, что позволяет с меньшими затратами 
увеличить их количество в устройстве\cite{fermi}. 
Для управления ими существует \textbf{warp scheduler}, выполняющий роль указателя на инструкции
соответствуя архитектуре SIMD. Данные для вычислений потоки берут из \textbf{локальной памяти} (shared memory), общей для
всех ядер. Достигается это с использованием \textbf{устройств загрузки и хранения} (load-store units), соответственно
способных загружать, а также сохранять данные в локальную память. Между всеми 32 ядрами вычислительного
устройства динамически распределяются
\textbf{регистры}, самая быстрая память, доступная им. У мультипроцессора в наличии намного больше регистров, чем могло быть
нужно для выполнения программы. Это сделано для сокрытия времени на загрузку памяти и быстрого переключения контекста,
подробнее - в разделе~\ref{effectiveness}.
 
Количество таких устройств в видеокарте определяется следующим образом:
\begin{equation*}
\text{Количество ядер в видеокарте / } 32  \text{, в случае Nvidia}
\end{equation*}
\begin{equation*}
\text{Количество ядер в видеокарте / } 64  \text{, в случае AMD}
\end{equation*}

В терминологии Nvidia, поток из всех (32) активных ядер вычислительного устройства образует \textbf{warp}, 
Например, видеокарта Nvidia Geforce GTX 1050 Ti имеет 768 ядер CUDA, и, соответственно, 24 warp.

\subsection{Основные понятия OpenCL}\label{general-opencl}

\textbf{OpenCL} "--- открытый для свободного пользования программный интерфейс для создания параллельных приложений, 
использующих многоядерные структуры как и центрального процессора (CPU), так и графического (GPU).
Использование API необходимо для обеспечения совместимости программы с различными устройствами\cite{opencl-intro}.

При построении задач, определяется \textbf{рабочее пространство} (NDRange), представляющее собой все возможные в рамках 
задачи значения индексов потоков. 
Размер рабочего пространства определяется программистом на этапе инициализации OpenCL программы.
Рабочее пространство может представлять:
\begin{itemize}
	\item одномерный массив длиной N элементов;
	\item двумерную сетку размерности NxM;
	\item трехмерное пространство размерностью NxMxP.
\end{itemize}

Код, выполняющийся параллельно на ядрах процессора, называется \textbf{kernel}. Копия kernel выполняется
для каждого индекса рабочего пространства и называется \textbf{work-item} с глобальным ID, соответствующим
некоторому ID рабочего пространства. Kernel для всех work-item в рабочем пространстве имеют одинаковый код
и входные параметры, но может иметь различный путь выполнения программы соответственно своему глобальному индексу -
индекс в рабочем пространстве, полученному с использованием функции \verb|get_global_id()|. Kernel в отличии
от остальной программы полностью выполняется на видеокарте\cite{opencl-spec}.

Группа work-item называется \textbf{work-group}, и за каждой группой закреплен собственный warp (см. предыдущий раздел),
в рамках которого work-item могут синхронизироваться. Для каждой рабочей группы существует ее индекс в рабочем
пространстве, и каждый work-item может узнать свой индекс внутри рабочей группы. Нетрудно заметить следующее 
соотношение:
\begin{equation*}
	\text{global ID } = \text{ group ID * размер группы } + \text{ local ID} 
\end{equation*}
Размер рабочей группы аналогично рабочему пространству определяется программистом.

Каждое ядро, выполняя заданный kernel, является work-item в некоторой рабочей группой, на которые разделено
рабочее пространство NDRange.

Рассмотрим на примере следующей схемы~\ref{entities} другие виды сущностей, c которыми будет взаимодействие 
в OpenCL.
\begin{itemize}
	\item Платформа "--- драйвер, модель взаимодействия OpenCL и устройства. Распространены платформы от следующих
	производителей: Nvidia, Intel, AMD.
	\item Программа "--- хостовая часть, организующая подготовку к вычислениям и набор kernel-подпрограмм.
	\item Kernel "--- программа, исполняющаяся на видеокарте в каждом ядре.
	\item Контекст "--- окружение, в котором исполняется kernel.
	\item Объект памяти "--- создаваемый в контексте объект.
	\item Буфер "--- произвольный массив данных.
\end{itemize}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{screenshots/opencl-entities}
	\caption{Основные сущности в OpenCL.}\label{entities}
\end{figure}

\section{Алгоритмы на видеокарте}
В данном разделе будет рассмотрена анализ и практическая реализация алгоритмов на видеокарте, включая:
\begin{itemize}
	\item описание общих требований к алгоритмам на основе доступа к памяти и параллельного исполнения;
	\item настройка среды разработки Microsoft Visual Studio 2017 под выполнение параллельных программ с использованием OpenCL;
	\item написание программ для задач, использующих входные данные разных размерностей.
\end{itemize}


\subsection{Требования к алгоритмам} \label{effectiveness}
Любой алгоритм можно вычислить на видеокарте, но эффективность в сравнении с реализацией на 
центральном процессоре зависит от корректного построения алгоритма для видеокарты.

Основным требованием к составлению алгоритма на видеокарте считается наличие 
массового параллелизма. Он заключается в том что задачу можно разбить на рабочие группы так, что
не будет требоваться постоянная синхронизация между work-item из разных рабочих групп.

Следует вспомнить, что все потоки в warp выполняют одинаковые инструкции в любой момент
времени. Какая инструкция будет выполняться следующей определяется с помощью warp scheduler, единого
для всех потоков в warp. Рассмотрим следующий фрагмент кода:

\begin{Verbatim}
if (predicate) {
    value = x[i];
}
else {
    value = y[i];
}
\end{Verbatim}

Учитывая сказанное выше, все потоки при срабатывания if-части должны выполнить внутреннюю часть,
однако это не совсем так, и если у потока предикат "--- \verb|False|, он будет спрятан от выполнения
внутренней части, аналогично и с \verb|else|-частью. Однако несмотря на то что результат выполнения 
конструкции \verb|if-else| будет верным, часть потоков будет простаивать, ожидая выполнение
маскированных для них частей. 

Данная ситуация называется code divergence, и она может стать причиной низкой производительности программы.
Этого можно избежать, если организовать код таким образом чтобы для всех потоков предикат
возвращал одинаковое значение, тогда конструкция не соответствующая ему будет пропущена указателем на инструкции.
Если это невозможно, то для эффективного выполнения алгоритма рекомендуется отказаться от многочисленных
сложных ветвлений, так как сложность выполнения фрагмента алгоритма будет вычисляться как сумма if- и else- частей
вместо максимума как в последовательных программах.  

При выборе размера рабочих групп стоит учитывать особенности алгоритма, однако, есть
некоторые общие правила, которых необходимо придерживаться.
\begin{enumerate}
	\item Размер рабочей группы не должен быть меньше warp.
	\item Размер рабочей группы должен быть кратен 32 (64 если используется AMD).
\end{enumerate}

В противном случае, некоторые потоки будут простаивать, ожидая пока остальные завершат свою работу

Как известно, операции с памятью являются одними из самых долгих по времени выполнения,
в связи с этим было решено сделать разбиение задач на рабочие группы, в результате
у видеокарт появился аналог имеющегося у процессоров hyper-threading. Он заключается в 
использовании каждым вычислительным устройством регистров для переключения контекста при задержке, созданной
обращением к памяти (latency)\cite{videocard-architecture}.

Другими словами, warp может быстро сохранить состояние
выполнения в данной рабочей группе и пока выполняется долгая операция обращения к памяти, вычислительное
устройство может переключиться на другой warp в рабочей группе, и если второй warp хочет выполнить
операцию обращения к памяти, то происходит возвращение к первому warp если доступ к памяти завершился, либо
активируется третий warp и так далее. Следствие "--- высокая вычислительная мощность 
и большая пропускная способность видеокарты\cite{warps}. 

Количество одновременно активных warp в рабочей группе определяется как минимум из:
\begin{itemize}
	\item количества регистров / количество используемых в warp регистров;
	\item количества локальной памяти / количество используемой локальной памяти;
	\item максимально допустимого количества warp (\verb|~10|).
\end{itemize}

В соответствии с этим существует величина \textbf{occupancy}, определяемая соотношением
\begin{equation*}
	\text{среднее кол-во активных warp } / \text{ максимальное кол-во активных warp} 
\end{equation*}

Не всегда высокий occupancy означает что программа имеет высокую производительность.
Например, если доступ к памяти в программе очень быстрый, только из регистров, 
то необходимости в сокрытии задержки и переключения контекста нет, и occupancy будет низким.

Однако, низкий occupancy и высокая задержка при обращении к памяти может означать что программа
написана не достаточно эффективно, и ей необходимы улучшения, если это возможно.

Чем больше на одном вычислителе warp "--- тем реже все warp оказываются в
состоянии <<ждем запрос памяти>> и тем реже вычислитель будет простаивать,
т.к. тем чаще у него находится рабочая группа в которой можно что-то
посчитать\cite{videocard-architecture}.

Если потоки из одного warp делают запрос к памяти, то эти
запросы склеются в столько запросов, сколькими кэш-линиями покрываются
запрошенные данные.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{screenshots/memory-res}
	\caption{Доступные ресурсы "--- память.}\label{mem}
\end{figure}

Другими словами, если потоки запрашивают данные, которые в памяти лежат подряд, то 
достигнутая пропускная способность будет максимальная так как запросы <<склеются>>.
Размер кэш-линии обычно от 32 до 128 байт.

Если приложение использует OpenCL 1.x, то размеры NDRange должны нацело (без остатка) делиться на размеры рабочих групп.
Там, где данные образуют NDRange с другим размером, необходимо самостоятельно изменить их чтобы выполнялось это условие,
например, добавлением нулей или средних значений, которые не будут значимо влиять на результат вычислений\cite{work-groups}.

В OpenCL 2.0 появилась новая возможность, в которой устранена данная проблема. Речь идет о так называемых неоднородных рабочих группах: 
выполняемый модуль OpenCL 2.0 может разделить NDRange на рабочие группы неоднородного размера по любому измерению. 
Если разработчик укажет размер рабочей группы, на который размер NDRange не делится нацело, выполняемый модуль разделит NDRange таким образом, 
чтобы создать как можно больше рабочих групп с указанным размером, а остальные рабочие группы будут иметь другой размер. 
Например, для NDRange размером 1918x1078 рабочих элементов при размере рабочей группы 16x16 элементов среда выполнения OpenCL 2.0 разделит NDRange, 
как показано на приведенном ниже рисунке~\ref{ndrange}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{screenshots/ndrange-selection}
	\caption{Разделение NDRange на рабочие группы разных размеров.}\label{ndrange}
\end{figure}


\subsection{Настройка среды разработки}
В данном разделе будет рассмотрен процесс настройки среды разработки и создания первого OpenCL-проекта.

В качестве среды разработки для программирования с использованием OpenCL выбрана Microsoft Visual Studio, 
язык программирования "--- C++.

На компьютер была установлена реализация OpenCL от Nvidia "--- Nvidia GPU Computing SDK. А
также программа CMake, являющаяся независимым от платформы инструментом для сборки проектов~\ref{cmake}.

С помощью графического интерфейса выберем расположение файлов исходного кода и места сборки проекта.
Директория с исходными файлами должны содержать текстовые файлы CMakeLists из приложения~\ref{pril-2}.
Если OpenCL установлен корректно, то нажатие кнопки <<Configure>> выведет найденные на компьютеры
файлы, связанные с OpenCL. Нажмем <<Generate>>, и перейдем в папку с проектом, в котором можно увидеть созданный
файл .sln проекта Microsoft Visual Studio, сконфигурированного под OpenCL.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{screenshots/cmake}
	\caption{Окно программы CMake-gui.}\label{cmake}
\end{figure}


\subsection{Инициализация OpenCL программы}
В данном разделе будут рассмотрены базовые функции, необходимые для инициализации параллельной программы
с использованием OpenCL. Данные функции будут предварять задачи из следующих разделов. 

Рассмотрим пример, взятый из руководства по OpenCL~\cite{opencl-guide}. С полным кодом,
содержащим комментарии, переведенными на русский язык, можно ознакомиться в приложении~\ref{pril-1},
файл HelloWorld.cpp. Обратим внимание на последовательность действий в функции main().
Многие понятия из данного раздела подробно описаны в~\ref{general-opencl}.

Сначала с помощью функции \verb|CreateContext()| создается контекст на основе
первой найденной на компьютере платформы. Далее для первого доступного устройства в контексте
создается командная очередь \newline \verb|clCreateCommandQueue()|, 
а в случае неудачи запускается функция очистки и программа завершается с кодом ошибки 1.

Из файла с исходным кодом kernel HelloWorld.cl создается OpenCL программа \verb|clCreateProgramWithSource()|. 
После этого создается и сам kernel на основе созданной <<программы>> \verb|clCreateKernel()|.

После этого создаются объекты памяти для конкретной задачи \newline \verb|clCreateBuffer()|, и каждый из них поочередно 
загружается в kernel с помощью \verb|clSetKernelArg()|.
Затем kernel ставится в очередь на выполнение \verb|clEnqueueNDRangeKernel()|, и после завершения работы, выводим в консоль буфер"=результат,
являющимся результатом выполнения данной OpenCL программы \verb|clEnqueueReadBuffer()|.

\subsection{Задачи на одномерных массивах}
Решим типовые задачи на одномерных массивах.

\subsubsection{Вычисление суммы ряда}
Одна из самых тривиальных задач "--- посчитать сумму двух векторов.
Даны векторы \textbf{a} и \textbf{b}, на основе их суммы должен получиться вектор \textbf{result}.
%https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/clEnqueueNDRangeKernel.html

\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/HelloWorld.cl}

Рассмотрим kernel для решения данной задачи. Каждый work-item, исполняя копию kernel, узнает
свой глобальный ID в рабочем пространстве с помощью \verb|get_global_id(0)|. Таким образом
он читает данные из видеопамяти соответствуя своему индексу. В основной программе выбран NDRange
размерности 1024 и \verb|local_work_size|, размер рабочей группы, равный 32.
Эти параметры переданы в функцию \verb|clEnqueueNDRangeKernel()| 

Пусть значения компонент первого вектор соответствуют номеру компоненты начиная с 0, а значения
компонент второго вектора соответствуют удвоенному номеру компоненты в векторе. Результат работы
данной программы представлен на изображении~\ref{sum-vector}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{screenshots/sum-vector}
	\caption{Результат работы программы по суммированию двух векторов.}\label{sum-vector}
\end{figure}

\subsubsection{Нахождение максимального префикса}
Усложним задачу, найдя для всего массива максимальную сумму на префиксе.
То есть, значение префиксной суммы для каждого элемента в массиве должно определяться суммой
всех предыдущих элементов массива включая его самого.

Данная задача просто решается в последовательных решениях, но требует значительной модификации
алгоритма для параллельных вычислений на видеокарте.



----

\subsection{Задачи на двумерных массивах}
Следующий набор задач использует в качестве входных данных двумерный массив. 

\subsubsection{Транспонирование матрицы}
Решим задачу транспонирования матрицы. Задача сводится к считыванию и записи данных в память, но как было описано ранее в разделе~\ref{effectiveness}, эти
операции являются очень медленными. 

В простейшей реализация kernel будет выглядеть следующим образом:

\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/Transpose.cl}

Результат работы программы представлен на изображении~\ref{transpose-res}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{screenshots/transpose-res-new}
	\caption{Результат работы программы по транспонированию матрицы. Для выравнивания элементам меньше 10 добавлены незначащие нули}\label{transpose-res}
\end{figure}

В этом kernel данные считываются построчно, и записываются в столбец. Заметим, что
операция считывания, очевидно, происходит в одной кэш-линии, и все work-item в рабочей группе за 
1 глобальную операцию получат данные из исходной матрицы. Запись, напротив, происходит в разные строки,
и данные не могут находиться в одной кэш-линии. Следовательно, на каждый активный warp
произойдет $~$32 глобальные операции записи, и это сильно замедлит выполнение алгоритма.

Данную проблему можно решить использованием локальной памяти для транспонирования в соответствии
с изображением~\ref{tile}. Задача переносится на tile (плитка), которые создаются в локальной памяти, 
доступ к которой происходит быстро. 

Задача условно делится на 3 части, разделенные функцией <<барьер>>:
\begin{enumerate}
	\item считывание из глобальной памяти в локальную (tile);
	\item транспонирование в локальной памяти (tile);
	\item запись из локальной памяти (tile) в глобальную.
\end{enumerate}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{screenshots/tile-transpose}
	\caption{Транспонирование матрицы с использованием <<плиток>>.}\label{tile}
\end{figure}

Код оптимизированного kernel:

\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/Transpose-tile.cl}

В данном коде используется функция \verb|get_local_id()| для определения позиция внутри рабочей группы,
и, соответственно, получения элемента плитки, с которым будет работать текущий work-item

%https://compscicenter.ru/courses/video_cards_computation/2018-autumn/classes/4194/


\subsubsection{Умножение матриц}
Задача умножения матриц является одной из типовых задач, решение которых имеет огромное преимущество 
при использовании видеокарты для вычисления~\ref{mul-naive}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{screenshots/matmul-naive}
	\caption{Умножение матриц A ($M \times K$) и B ($K \times N$).}\label{mul-naive}
\end{figure}

Как и в предыдущей задаче про транспонирование рассмотрим наиболее простое решение данной задачи.
Каждый поток будет считывать для соответствующей ему ячейки результирующей матрицы строку и столбец исходной.

\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/Matmul-naive.cl}

Можно заметить, что для каждой ячейки результирующей матрицы ($N \times M$ ячеек) происходит $2 \times K$ 
обращений к памяти, в массиве A он эффективный так как его элементы берутся последовательно, а в массиве B "---
нет, и при получении элементов из столбца может быть выполнено до 32 обращений к памяти вместо одного. Таким образом происходит
O($M \times N \times K$) обращений к памяти, что является существенным фактором медленной работы алгоритма.

Оптимизируем алгоритм, использовав модифицированную версию подхода, представленную в предыдущей задаче. Разобьем задачу на
фрагменты в локальной памяти, используемые потоками одной рабочей группы~\ref{mul-smart}. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{screenshots/matmul-smart}
	\caption{Использование локальной памяти при умножении матриц.}\label{mul-smart}
\end{figure}

Преимущество подобного решения "--- снижение длительности операций считывания памяти за счет того
что каждый warp работает в собственной локальной памяти, а также за счет считывания данных построчно (см. раздел~\ref{effectiveness}).

Код kernel для эффективного умножения матриц:
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/Matmul-smart.cl}

\newpage
%===========================================
% Раздел "Заключение"
\conclusion
В настоящей работе была изучена технология OpenCL для параллельных вычислений на видеокарте.
Корректно построенные параллельные алгоритмы на видеокарте показывают высокую производительность за
счет использования большого числа ядер. Эффективность алгоритма зависит от поддержания массового
параллелизма, корректного ветвления кода, а также правильного доступа к памяти.

Была изучена архитектура видеокарты и связанные с ней понятия OpenCL, а также решены некоторые задачи
с исходными данных разных размерностей
путем написания высокопроизводительных OpenCL программ, состоящих из хостовых и kernel частей.

%Библиографический список, составленный вручную, без использования BibTeX
%
%\begin{thebibliography}{99}
%  \bibitem{Ione} Источник 1.
%  \bibitem{Itwo} Источник 2
%\end{thebibliography}

%Библиографический список, составленный с помощью BibTeX
%
\bibliographystyle{gost780uv}
\bibliography{thesis}

% Окончание основного документа и начало приложений
% Каждая последующая секция документа будет являться приложением

\appendix

\section{Листинг программы}\label{pril-1}
Вычисление суммы двух массивов.
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/HelloWorld.cpp}
Kernel для данной задачи.
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/HelloWorld.cl}

Kernel для <<наивной>> реализации задачи транспонирования матрицы.
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/transpose.cl}

Kernel для эффективной реализации задачи транспонирования матрицы.
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/transpose-tile.cl}

\section{Листинг сборочных файлов CMake}\label{pril-2}
Код сборочного файла CMakeLists.txt
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/CMakeLists.txt}

Пример сборочного файла CMakeLists.txt для проекта с транспонированием матрицы
\VerbatimInput[fontsize=\small, numbers=left, numbersep=2pt]{code/CMakeLists.txt}

\end{document}
